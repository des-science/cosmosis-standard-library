"""
The likelihood module for the DES Y5 SN simulated dataset
author: Sujeong Lee
"""

from cosmosis.gaussian_likelihood import GaussianLikelihood
from cosmosis.datablock import names
import os
import numpy as np
import pandas as pd 

# Default is to use DES only SN. To use DES+LOWZ SN, set the data_file 
# and covmat_file parameters in the ini file 
# default sim datavector and cov are generated by Ryan Camilleri 
default_data_file = os.path.join(os.path.split(__file__)[0], "DESONLY/hubble_diagram.txt")
default_covmat_file = os.path.join(os.path.split(__file__)[0], "DESONLY/covsys_000.txt")
# M_fid is absolute magnitude for data
M_fid = -19.35 
# Both data and theory are the distance modulus. 
# To marginalize the absolute magnitude M, I subtracted M_fid (fixed value) from data and 
# also subtract M (varying params) from theory. 

class DESY5SNLikelihood(GaussianLikelihood):
    x_section = names.distances
    x_name = "z"
    y_section = names.distances
    #y_name = "mu"
    y_name = "D_A"
    like_name = "desy5sn"


    def build_data(self):
        """
        Run once at the start to load in the data vectors.

        Returns x, y where x is the independent variable (redshift in this case)
        and y is the Gaussian-distribured measured variable (magnitude in this case).

        """
        filename = self.options.get_string("data_file", default=default_data_file)
        print("Loading DES Y5 SN data from {}".format(filename))
        data = pd.read_csv(filename,delim_whitespace=True, comment='#')
        #import ipdb
        #ipdb.set_trace()
        self.origlen = len(data)
        # The only columns that we actually need here are the redshift,
        # distance modulus and distance modulus error

        self.ww = (data['zHD']>0.00) 
        #use the vpec corrected redshift for zCMB 
        self.zCMB = data['zHD'][self.ww] 
        self.zHEL = data['zHEL'][self.ww]
        # distance modulus
        self.mu_obs = data['MU'][self.ww]

        # DES Y5 SN data provides distance modulus, so we need to convert it to the apparent magnitude first 
        # magnitude obtained by subtracting the absolute magnitude from the distance modulus
        self.m_obs = self.mu_obs + M_fid
        # Constant substraction (F_fid) doesn't affect error (true?) so we use mu observational err as mag_obs_err 
        self.mag_obs_err = data['MUERR'][self.ww]

        # Return this to the parent class, which will use it
        # when working out the likelihood
        print(f"Found {len(self.zCMB)} DES SN 5 supernovae (or bins if you used the binned data file)")
        return self.zCMB, self.m_obs

    def build_covariance(self):
        """Run once at the start to build the covariance matrix for the data"""
        filename = self.options.get_string("covmat_file", default=default_covmat_file)
        print("Loading DESY5 SN covariance from {}".format(filename))
        # The file format for the covariance has the first line as an integer
        # indicating the number of covariance elements, and the the subsequent
        # lines being the elements.
        # This data file is just the systematic component of the covariance - 
        # we also need to add in the statistical error on the magnitudes
        # that we loaded earlier
        f = open(filename)
        line = f.readline()
        n = int(line)
        C = np.zeros((n,n))
        for i in range(n):
            for j in range(n):
                C[i,j] = float(f.readline())

        # Now add in the statistical error to the diagonal
        for i in range(n):
            C[i,i] += self.mag_obs_err[i]**2
        f.close()

        # Return the covariance; the parent class knows to invert this
        # later to get the precision matrix that we need for the likelihood.

        C = C[self.ww][:, self.ww]

        return C

    def extract_theory_points(self, block):
        """
        Run once per parameter set to extract the mean vector that our
        data points are compared to.  For the Hubble flow set, we compare to the 
        cosmological model. For the calibrators we compare to the Cepheid distances.
        """
        import scipy.interpolate

        # Pull out theory mu and z from the block.
        theory_x = block[self.x_section, self.x_name]
        theory_y = block[self.y_section, self.y_name]
        theory_ynew = self.zCMB * np.nan

        # Interpolation function of theory so we can evaluate at redshifts of the data
        f = scipy.interpolate.interp1d(theory_x, theory_y, kind=self.kind)
        
        zcmb = self.zCMB
        zhel = self.zHEL
        theory_ynew = 5.0*np.log10((1.0+zcmb)*(1.0+zhel)*np.atleast_1d(f(zcmb)))+25.

        # Add the absolute supernova magnitude and return
        M = block[names.supernova_params, "M"]
        return theory_ynew + M


# This takes our class and turns it into 
setup, execute, cleanup = DESY5SNLikelihood.build_module()
